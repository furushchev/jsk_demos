<launch>
  <arg name="use_throttle" default="false" />
  <arg name="use_speech_recognition" default="false" />
  <arg name="use_speech_synthesis" default="true" />
  <arg name="respawn" default="true" />

  <arg name="camera" default="kinect_head_external" />
  <arg name="throttle_prefix"     if="$(arg use_throttle)" default="throttled/" />
  <arg name="throttle_prefix" unless="$(arg use_throttle)" default="" />

  <arg name="input_image" default="/$(arg camera)/rgb/$(arg throttle_prefix)image_rect_color" />
  <arg name="input_camera_info" default="/$(arg camera)/rgb/$(arg throttle_prefix)camera_info" />
  <arg name="input_depth" default="/$(arg camera)/depth_registered/$(arg throttle_prefix)image_rect" />

  <arg name="machine" default="external" />

  <include file="$(find interactive_behavior_201409)/pr2.machine" />

  <group if="$(arg use_speech_synthesis)">
    <node name="gtts" pkg="ros_gtts" type="ros_gtts_node.py" machine="c1"/>

    <node pkg="sound_play" type="soundplay_node.py" name="robotsound_gtts"
          machine="c1" respawn="$(arg respawn)">
      <remap from="sound_play" to="robotsound_gtts" />
      <remap from="robotsound" to="robotsound_gtts" />
      <env name="PATH" value="$(find ros_gtts)/bin:$(env PATH)" />
    </node>
  </group>

  <group if="$(arg use_speech_recognition)">
    <node name="audio_capture" pkg="audio_capture" type="audio_capture"
          machine="c2" output="screen">
      <rosparam>
        format: wave
        channels: 1
        depth: 16
        sample_rate: 16000
        device: plughw:1
      </rosparam>
    </node>
    <node name="speech_recognition"
          pkg="ros_speech_recognition" type="speech_recognition_node.py"
          machine="c2" output="screen">
      <remap from="sound_play" to="robotsound" />
      <rosparam>
        engine: Google
        language: en-US
        continuous: true
      </rosparam>
    </node>
  </group>

  <group ns="interaction">
    <node name="people_pose_estimation"
          pkg="jsk_perception" type="people_pose_estimation_2d.py"
          output="screen" respawn="$(arg respawn)"
          machine="$(arg machine)">
      <remap from="~input" to="$(arg input_image)" />
      <remap from="~input/info" to="$(arg input_camera_info)" />
      <remap from="~input/depth" to="$(arg input_depth)" />
      <rosparam subst_value="true">
        gpu: 0
        model_file: $(optenv JSK_DATA_CACHE_DIR /etc/ros/jsk_data)/jsk_perception/pose_estimation_2d_chainermodel.pkl
        with_depth: true
        scales: [0.38]
        stride: 8
      </rosparam>
    </node>

    <node name="face_pose_estimation"
          pkg="jsk_perception" type="face_pose_estimation.py"
          output="screen" machine="$(arg machine)" respawn="$(arg respawn)">
      <remap from="~input" to="$(arg input_image)"/>
      <remap from="~input/pose_2d" to="people_pose_estimation/pose_2d" />
      <remap from="~input/pose" to="people_pose_estimation/pose" />
      <rosparam subst_value="true">
        gpu: 0
        model_path: auto
      </rosparam>
    </node>

    <node name="rect_array_to_face_array"
          pkg="interactive_behavior_201409" type="rect_array_to_face_array.py"
          output="screen" machine="$(arg machine)" respawn="$(arg respawn)">
      <remap from="~input" to="face_pose_estimation/output/rects" />
    </node>

    <node name="manager"
          pkg="jsk_topic_tools" type="standalone_complexed_nodelet"
          output="screen" respawn="$(arg respawn)"
          machine="$(arg machine)">
      <rosparam subst_value="true">
        nodelets:
        - name: depth_to_mask
          type: jsk_pcl_utils/PointCloudToMaskImage
          remappings:
          - from: ~input/depth
            to: $(arg input_depth)
        - name: apply_mask
          type: jsk_perception/ApplyMaskImage
          remappings:
          - from: ~input
            to: $(arg input_image)
          - from: ~input/mask
            to: depth_to_mask/output
        - name: face_detection
          type: opencv_apps/face_detection
          remappings:
          - from: image
            to: apply_mask/output
        - name: face_recognition
          type: opencv_apps/face_recognition
          remappings:
          - from: image
            to: $(arg input_image)
          - from: faces
            to: rect_array_to_face_array/output
      </rosparam>
    </node>

    <rosparam ns="depth_to_mask">
      z_near: 1.5
      z_far: 3.0
    </rosparam>

    <rosparam ns="apply_mask">
      clip: false
      approximate_sync: true
    </rosparam>

    <rosparam ns="face_detection">
      use_camera_info: false
      debug_view: false
      face_cascade_name: /usr/share/opencv/haarcascades/haarcascade_frontalface_alt.xml
      eyes_cascade_name: /usr/share/opencv/haarcascades/haarcascade_eye_tree_eyeglasses.xml
    </rosparam>

    <rosparam ns="face_recognition"
              subst_value="true">
      model_threshold: 4300.0
      data_dir: $(optenv JSK_DATA_CACHE_DIR /etc/ros/jsk_data)/opencv_apps/face_data
    </rosparam>

    <node name="people_attention_tracker" pkg="interactive_behavior_201409" type="people_attention_tracker.py"
          output="screen">
      <remap from="~input/pose" to="face_pose_estimation/output/pose" />
      <remap from="~input/face" to="face_recognition/output" />
      <remap from="~output" to="attention" />
      <rosparam>
        fixed_frame_id: odom_combined
        distance_threshold: 0.25
        timeout_threshold: 3.0
        face_recognition_threshold: 4300.0
      </rosparam>
    </node>

    <node name="people_attention_visualizer"
          pkg="jsk_rviz_plugins" type="classification_result_visualizer.py">
      <remap from="~input/classes" to="people_attention_tracker/output/attention" />
      <remap from="~input/poses"   to="face_pose_estimation/output/pose" />
      <param name="text_size" value="0.1" />
    </node>

    <node name="sound_attention_tracker"
          pkg="interactive_behavior_201409" type="sound_attention_tracker.py">
      <remap from="~output" to="attention" />
      <rosparam>
        mean_threshold: 0.05
        covariance_threshold: 0.25
      </rosparam>
    </node>

  </group>

  <node name="idle_behavior"
        pkg="interactive_behavior_201409" type="idle-behavior.l"/>
</launch>
